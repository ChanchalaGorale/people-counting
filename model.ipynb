{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43af2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "import cv2\n",
    "import scipy.io\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D, Activation, MaxPooling2D, Add, Conv2D, MaxPool2D, Dense,\n",
    "                                     Flatten, InputLayer, BatchNormalization, Input, Embedding, Permute,\n",
    "                                     Dropout, RandomFlip, RandomRotation, LayerNormalization, MultiHeadAttention,\n",
    "                                     RandomContrast, Rescaling, Resizing, Reshape,LeakyReLU)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
    "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.regularizers import L2, L1\n",
    "from tensorflow.keras.initializers import RandomNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "485d0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_X,IN_Y=768,1024\n",
    "OUT_X,OUT_Y=96,128\n",
    "SUBSAMPLING_FACTOR=IN_X//OUT_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3405a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_distribution(x,u=0,sigma=10):\n",
    "    return np.expand_dims(1/(np.sqrt(2*np.pi*(sigma**2)))*np.exp(-(0.5)*(((x-u)/sigma)**2)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be539db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_density_map_gaussian(im,points,gaussian_radius=4):\n",
    "    density_map=np.zeros((OUT_X,OUT_Y))\n",
    "    w,h=OUT_Y,OUT_X\n",
    "    num_gt=len(points)\n",
    "    \n",
    "    for point in points:\n",
    "        point=np.round(point).astype(int)\n",
    "        point[0],point[1]=min(h-1,point[1]),min(w-1,point[0])\n",
    "        x=np.linspace(-gaussian_radius,gaussian_radius,(gaussian_radius*2)+1)\n",
    "        gaussian_map=np.multiply(gauss_distribution(x),gauss_distribution(x).T)\n",
    "        gaussian_map/=np.sum(gaussian_map)\n",
    "        \n",
    "        x_left,x_right,y_up,y_down=0,gaussian_map.shape[1],0,gaussian_map.shape[0]\n",
    "        if point[1]<gaussian_radius:\n",
    "            x_left=gaussian_radius-point[1]\n",
    "        if point[0]<gaussian_radius:\n",
    "            y_up=gaussian_radius-point[0]\n",
    "        if point[1]+gaussian_radius>=w:\n",
    "            x_right=gaussian_map.shape[1]-(gaussian_radius+point[1]-w)-1\n",
    "        if point[0]+gaussian_radius>=h:\n",
    "            y_down=gaussian_map.shape[0]-(gaussian_radius+point[0]-h)-1\n",
    "        density_map[\n",
    "            max(0,point[0]-gaussian_radius):min(density_map.shape[0],point[0]+gaussian_radius+1),\n",
    "            max(0,point[1]-gaussian_radius):min(density_map.shape[1],point[1]+gaussian_radius+1),\n",
    "        ]+=gaussian_map[y_up:y_down,x_left:x_rigtht]\n",
    "    density_map/=np.sum(density_map/len(points))\n",
    "    return density_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed6f8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__ (self, images, maps, batch_size,SUBSAMPLING_FACTOR=8):\n",
    "\n",
    "        self.images = images\n",
    "        self.maps = maps\n",
    "        self.batch_size = batch_size\n",
    "        self.train_image_list=os.listdir(images)\n",
    "        self.SUBSAMPLING_FACTOR=SUBSAMPLING_FACTOR\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.train_image_list)/self.batch_size))\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.__data_generation(idx)\n",
    "        return x,y\n",
    "  \n",
    "    def __data_generation(self, idx):\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for j in range(idx*self.batch_size, (idx+1)*self.batch_size):\n",
    "            \n",
    "            im_array=img_to_array(load_img(self.images+os.listdir(self.images)[j],target_size=(IN_X,IN_Y)))\n",
    "            im_array/=255.\n",
    "            im_array[:,:,0]=(im_array[:,:,0]-np.mean(im_array[:,:,0]))/np.std(im_array[:,:,0])\n",
    "            im_array[:,:,1]=(im_array[:,:,1]-np.mean(im_array[:,:,1]))/np.std(im_array[:,:,1])\n",
    "            im_array[:,:,2]=(im_array[:,:,2]-np.mean(im_array[:,:,2]))/np.std(im_array[:,:,2])\n",
    "            x.append(im_array)\n",
    "            mat=scipy.io.loadmat(self.maps+os.listdir(self.maps)[j])\n",
    "            points=mat['image_info'][0][0][0][0][0]\n",
    "            points/=self.SUBSAMPLING_FACTOR\n",
    "            \n",
    "            density_map_present=get_density_map_gaussian(im_array,points,sigma=5)\n",
    "            y.append(density_map_present)\n",
    "        return tf.convert_to_tensor(x),tf.convert_to_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7edb635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images='...'\n",
    "train_maps='...'\n",
    "val_images='...'\n",
    "val_maps='...'\n",
    "\n",
    "LR=1e-4\n",
    "BATCH_SIZE=1\n",
    "EPOCH=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2c89677",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m DataGenerator(train_images, train_maps,BATCH_SIZE,BATCH_SIZE)\n",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mDataGenerator.__init__\u001b[0;34m(self, images, maps, batch_size, SUBSAMPLING_FACTOR)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaps \u001b[38;5;241m=\u001b[39m maps\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_image_list\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mlistdir(images)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSUBSAMPLING_FACTOR\u001b[38;5;241m=\u001b[39mSUBSAMPLING_FACTOR\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(train_images, train_maps,BATCH_SIZE,BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8bca7d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When providing `inputs` as a list/tuple, all values in the list/tuple must be KerasTensors. Received: inputs=[[<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_20>]] including invalid value [<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_20>] of type <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m     block4_conv3\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock4_conv3\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(\n\u001b[1;32m     10\u001b[0m         inputs\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39minputs],outputs\u001b[38;5;241m=\u001b[39m[block4_conv3]\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m get_base_model()\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mget_base_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m VGG16(\n\u001b[1;32m      3\u001b[0m     weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(IN_X,IN_Y,\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      5\u001b[0m     include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,)\n\u001b[1;32m      7\u001b[0m block4_conv3\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock4_conv3\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(\n\u001b[1;32m     10\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39minputs],outputs\u001b[38;5;241m=\u001b[39m[block4_conv3]\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:143\u001b[0m, in \u001b[0;36mModel.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functional_init_arguments(args, kwargs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m Model:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional\u001b[38;5;241m.\u001b[39mFunctional(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(Model, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:122\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flat_inputs:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll `inputs` values must be KerasTensors. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m including invalid value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 122\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flat_outputs:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n",
      "\u001b[0;31mValueError\u001b[0m: When providing `inputs` as a list/tuple, all values in the list/tuple must be KerasTensors. Received: inputs=[[<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_20>]] including invalid value [<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_20>] of type <class 'list'>"
     ]
    }
   ],
   "source": [
    "def get_base_model():\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        input_shape=(IN_X,IN_Y,3),\n",
    "        include_top=False,)\n",
    "    \n",
    "    block4_conv3=[base_model.get_layer(layer_name).output for layer_name in [\"block4_conv3\"]]\n",
    "    \n",
    "    return Model(\n",
    "        inputs=[base_model.inputs],outputs=[block4_conv3]\n",
    "    )\n",
    "\n",
    "get_base_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53693ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When providing `inputs` as a list/tuple, all values in the list/tuple must be KerasTensors. Received: inputs=[[<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_40>]] including invalid value [<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_40>] of type <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(IN_X,IN_Y,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m x\u001b[38;5;241m=\u001b[39mget_base_model()(inputs)\n\u001b[1;32m      3\u001b[0m init\u001b[38;5;241m=\u001b[39mRandomNormal(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      5\u001b[0m x\u001b[38;5;241m=\u001b[39mConv2D(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, dilation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,kernel_iniitalizer\u001b[38;5;241m=\u001b[39minit,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mget_base_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m VGG16(\n\u001b[1;32m      3\u001b[0m     weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m(IN_X,IN_Y,\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      5\u001b[0m     include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,)\n\u001b[1;32m      7\u001b[0m block4_conv3\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock4_conv3\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Model(\n\u001b[1;32m     10\u001b[0m     inputs\u001b[38;5;241m=\u001b[39m[base_model\u001b[38;5;241m.\u001b[39minputs],outputs\u001b[38;5;241m=\u001b[39m[block4_conv3]\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/models/model.py:143\u001b[0m, in \u001b[0;36mModel.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m functional_init_arguments(args, kwargs) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m Model:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional\u001b[38;5;241m.\u001b[39mFunctional(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(Model, \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/utils/tracking.py:26\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m DotNotTrackScope():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/src/models/functional.py:122\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flat_inputs:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll `inputs` values must be KerasTensors. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m including invalid value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 122\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m flat_outputs:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, backend\u001b[38;5;241m.\u001b[39mKerasTensor):\n",
      "\u001b[0;31mValueError\u001b[0m: When providing `inputs` as a list/tuple, all values in the list/tuple must be KerasTensors. Received: inputs=[[<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_40>]] including invalid value [<KerasTensor shape=(None, 768, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_40>] of type <class 'list'>"
     ]
    }
   ],
   "source": [
    "inputs=tf.keras.Input(shape=(IN_X,IN_Y,3))\n",
    "x=get_base_model()(inputs)\n",
    "init=RandomNormal(0.01)\n",
    "\n",
    "x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(512, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(256, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(128, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(64, (3,3), activation = 'relu', dilation_rate=2,kernel_iniitalizer=init,padding='same')(x)\n",
    "x=Conv2D(1, (1,1), activation = 'relu', dilation_rate=1,kernel_iniitalizer=init,padding='same')(x)\n",
    "\n",
    "out=Reshape((96,128))(x)\n",
    "model=tf.keras.Model(inputs=inputs,outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb431c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = Adam(learning_rate = LR),\n",
    "    metrics='accuracy',\n",
    "    run_eagerly = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath='...'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCH,\n",
    "    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9097b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN ='...'\n",
    "\n",
    "im_array=img_to_array(load_img(train_image+IN_'.jpg',target_size=(IN_X,IN_Y)))\n",
    "im_array/=255.\n",
    "im_array[:,:,0]=(im_array[:,:,0]-np.mean(im_array[:,:,0]))/np.std(im_array[:,:,0])\n",
    "im_array[:,:,1]=(im_array[:,:,1]-np.mean(im_array[:,:,1]))/np.std(im_array[:,:,1])\n",
    "im_array[:,:,2]=(im_array[:,:,2]-np.mean(im_array[:,:,2]))/np.std(im_array[:,:,2])\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imhow(im_array)\n",
    "\n",
    "output=mode.predict(tf.expand_dims(im_array,axis=0))\n",
    "output=np.reshape(output,(OUT_X,OUT_Y))\n",
    "\n",
    "n_people=np.sum(output)\n",
    "mat=scipy.io.loadmat(train_maps+'GT_'+IN+'.mat')\n",
    "points=mat['image_info'][0][0][0][0][0]\n",
    "points/=SUBSAMPLING_FACTOR\n",
    "\n",
    "num_gt=np.squeeze(points).shape[0]\n",
    "print(\"The actual number of people is=\",num_gt)\n",
    "print(\"The predicted number of people is =\",n_people)\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e13144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aee25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d648cb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2969d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03870d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904f563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e696687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341c339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389970de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb33a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c241d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6411b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f04b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664b288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff384f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88001ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020093da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9daf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b824459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a808f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c31872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c919c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f2c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9dfce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f10a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c93bf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576701d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b529a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20449ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd358fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b0b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da7590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea830b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb605f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45080091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5094b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699536e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314cbd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc19d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2901fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4714bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a17a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5428b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008dafc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e0747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53147809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30074780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bfdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0399fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde760aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e02ef41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c9e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92af5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb6df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b3bb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e83e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e2f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f7b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbab9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3181fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
